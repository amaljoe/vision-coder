{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b3262ca-3295-4546-8ab0-f48156a4a08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b34064aa2749aba6076342cf67604d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type qwen3_vl to instantiate a model of type qwen2_5_vl. This is not supported for all configurations of models and can yield errors.\n",
      "Unrecognized keys in `rope_parameters` for 'rope_type'='default': {'mrope_interleaved'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c610ab73a0423781809df5540ed758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82304b943be6447f86bb3e98e350db47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d576fdbd4ad443f98492018e26742685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93020ba34c540dbbdc3d2031bbf6e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qwen2_5_VLForConditionalGeneration LOAD REPORT from: Qwen/Qwen3-VL-8B-Instruct\n",
      "Key                                                            | Status     | \n",
      "---------------------------------------------------------------+------------+-\n",
      "model.language_model.layers.{0...35}.self_attn.q_norm.weight   | UNEXPECTED | \n",
      "model.visual.patch_embed.proj.bias                             | UNEXPECTED | \n",
      "model.visual.blocks.{0...26}.mlp.linear_fc2.bias               | UNEXPECTED | \n",
      "model.visual.blocks.{0...26}.mlp.linear_fc2.weight             | UNEXPECTED | \n",
      "model.language_model.layers.{0...35}.self_attn.k_norm.weight   | UNEXPECTED | \n",
      "model.visual.blocks.{0...26}.mlp.linear_fc1.weight             | UNEXPECTED | \n",
      "model.visual.blocks.{0...26}.norm2.bias                        | UNEXPECTED | \n",
      "model.visual.blocks.{0...26}.norm1.bias                        | UNEXPECTED | \n",
      "model.visual.merger.linear_fc1.bias                            | UNEXPECTED | \n",
      "model.visual.deepstack_merger_list.{0, 1, 2}.linear_fc2.bias   | UNEXPECTED | \n",
      "model.visual.deepstack_merger_list.{0, 1, 2}.linear_fc1.bias   | UNEXPECTED | \n",
      "model.visual.blocks.{0...26}.mlp.linear_fc1.bias               | UNEXPECTED | \n",
      "model.visual.deepstack_merger_list.{0, 1, 2}.norm.bias         | UNEXPECTED | \n",
      "model.visual.deepstack_merger_list.{0, 1, 2}.norm.weight       | UNEXPECTED | \n",
      "model.visual.deepstack_merger_list.{0, 1, 2}.linear_fc1.weight | UNEXPECTED | \n",
      "model.visual.merger.linear_fc2.bias                            | UNEXPECTED | \n",
      "model.visual.deepstack_merger_list.{0, 1, 2}.linear_fc2.weight | UNEXPECTED | \n",
      "model.visual.pos_embed.weight                                  | UNEXPECTED | \n",
      "model.visual.merger.linear_fc2.weight                          | UNEXPECTED | \n",
      "model.visual.merger.norm.bias                                  | UNEXPECTED | \n",
      "model.visual.merger.linear_fc1.weight                          | UNEXPECTED | \n",
      "model.visual.merger.norm.weight                                | UNEXPECTED | \n",
      "model.language_model.layers.{0...35}.self_attn.v_proj.bias     | MISSING    | \n",
      "model.visual.blocks.{0...26}.mlp.up_proj.weight                | MISSING    | \n",
      "model.visual.blocks.{0...26}.mlp.gate_proj.bias                | MISSING    | \n",
      "model.visual.blocks.{0...26}.mlp.gate_proj.weight              | MISSING    | \n",
      "model.visual.blocks.{0...26}.mlp.down_proj.bias                | MISSING    | \n",
      "model.visual.blocks.{0...26}.mlp.down_proj.weight              | MISSING    | \n",
      "model.language_model.layers.{0...35}.self_attn.k_proj.bias     | MISSING    | \n",
      "model.language_model.layers.{0...35}.self_attn.q_proj.bias     | MISSING    | \n",
      "model.visual.blocks.{0...26}.mlp.up_proj.bias                  | MISSING    | \n",
      "model.visual.merger.ln_q.weight                                | MISSING    | \n",
      "model.visual.merger.mlp.{0, 2}.bias                            | MISSING    | \n",
      "model.visual.merger.mlp.{0, 2}.weight                          | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f94a11560b4ababf07b5c9451e80ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/269 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import torch\n",
    "\n",
    "# default: Load the model on the available device(s)\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen3-VL-8B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n",
    "# model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "#     \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "\n",
    "# default processer\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8dc5fa3-4c13-4563-ab90-579be67fd13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "    <title>User Profile</title>\n",
      "    <style>\n",
      "    * {\n",
      "    ma\n"
     ]
    }
   ],
   "source": [
    "with open('scratch_web.html', 'r') as f:\n",
    "    html = f.read()\n",
    "\n",
    "print(html[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63f5b538-1293-43b3-a4fa-f06a8f53f102",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_vision_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 40\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Preparation for inference\u001b[39;00m\n\u001b[1;32m     37\u001b[0m text \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m     38\u001b[0m     messages, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     39\u001b[0m )\n\u001b[0;32m---> 40\u001b[0m image_inputs, video_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_vision_info\u001b[49m(messages)\n\u001b[1;32m     41\u001b[0m inputs \u001b[38;5;241m=\u001b[39m processor(\n\u001b[1;32m     42\u001b[0m     text\u001b[38;5;241m=\u001b[39m[text],\n\u001b[1;32m     43\u001b[0m     images\u001b[38;5;241m=\u001b[39mimage_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     48\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process_vision_info' is not defined"
     ]
    }
   ],
   "source": [
    "# The default range for the number of visual tokens per image in the model is 4-16384.\n",
    "# You can set min_pixels and max_pixels according to your needs, such as a token range of 256-1280, to balance performance and cost.\n",
    "# min_pixels = 256*28*28\n",
    "# max_pixels = 1280*28*28\n",
    "# processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": \"scratch_ss.png\",\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Give HTML and CSS for the reference UI.\"},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": html},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": \"scratch_ss2.png\",\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Rendered image from your code is given above. Update HTML + CSS based on the feedback from render to make it exactly like reference UI\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Preparation for inference\n",
    "text = processor.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "image_inputs, video_inputs = process_vision_info(messages)\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=image_inputs,\n",
    "    videos=video_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = inputs.to(\"cuda\")\n",
    "\n",
    "# Inference: Generation of the output\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=4096)\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")\n",
    "print(output_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87c10a89-b7fa-4483-a470-bc054df926ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef04b85e5194496b8f957553b424c48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor, AutoConfig\n",
    "import torch\n",
    "\n",
    "model_name = \"Qwen/Qwen3-VL-8B-Instruct\"\n",
    "\n",
    "# 1. Load config FIRST\n",
    "config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# 2. Patch the broken field\n",
    "if not hasattr(config.text_config, \"pad_token_id\"):\n",
    "    config.text_config.pad_token_id = 0   # Qwen uses 0 as pad by default\n",
    "\n",
    "# (optional but safe)\n",
    "if not hasattr(config, \"pad_token_id\"):\n",
    "    config.pad_token_id = 0\n",
    "\n",
    "# 3. Now load model with patched config\n",
    "# model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
    "#     model_name,\n",
    "#     config=config,\n",
    "#     torch_dtype=\"auto\",\n",
    "#     device_map=\"auto\",\n",
    "#     trust_remote_code=True\n",
    "# )\n",
    "\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n",
    "model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen3-VL-8B-Instruct\",\n",
    "    dtype=torch.bfloat16,\n",
    "    config=config,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen3-VL-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ea3d20-3a73-4028-a0fd-9fa2980bed8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing `generation_config` together with generation-related arguments=({'max_new_tokens'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```html\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "    <title>User Profile</title>\n",
      "    <style>\n",
      "        body {\n",
      "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
      "            line-height: 1.6;\n",
      "            color: #333;\n",
      "            max-width: 900px;\n",
      "            margin: 0 auto;\n",
      "            padding: 20px;\n",
      "            background-color: #f9f9f9;\n",
      "        }\n",
      "        \n",
      "        h1, h2, h3 {\n",
      "            color: #2c3e50;\n",
      "        }\n",
      "        \n",
      "        .section {\n",
      "            margin-bottom: 30px;\n",
      "        }\n",
      "        \n",
      "        .section h2 {\n",
      "            margin-top: 0;\n",
      "            padding-bottom: 10px;\n",
      "            border-bottom: 1px solid #e0e0e0;\n",
      "        }\n",
      "        \n",
      "        .badge-container {\n",
      "            display: flex;\n",
      "            flex-wrap: wrap;\n",
      "            gap: 20px;\n",
      "            margin-top: 20px;\n",
      "        }\n",
      "        \n",
      "        .badge-card {\n",
      "            flex: 1 1 300px;\n",
      "            background: #fff;\n",
      "            border: 1px solid #e0e0e0;\n",
      "            border-radius: 8px;\n",
      "            padding: 20px;\n",
      "            text-align: center;\n",
      "            box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
      "        }\n",
      "        \n",
      "        .badge-icon {\n",
      "            width: 80px;\n",
      "            height: 80px;\n",
      "            margin: 0 auto 15px;\n",
      "        }\n",
      "        \n",
      "        .badge-text {\n",
      "            font-size: 14px;\n",
      "            color: #666;\n",
      "        }\n",
      "        \n",
      "        .badge-list {\n",
      "            list-style: none;\n",
      "            padding: 0;\n",
      "            margin: 0;\n",
      "        }\n",
      "        \n",
      "        .badge-item {\n",
      "            display: flex;\n",
      "            justify-content: space-between;\n",
      "            align-items: center;\n",
      "            padding: 8px 0;\n",
      "            border-bottom: 1px solid #eee;\n",
      "        }\n",
      "        \n",
      "        .badge-item:last-child {\n",
      "            border-bottom: none;\n",
      "        }\n",
      "        \n",
      "        .badge-label {\n",
      "            background-color: #333;\n",
      "            color: white;\n",
      "            padding: 4px 12px;\n",
      "            border-radius: 4px;\n",
      "            font-size: 14px;\n",
      "            font-weight: 500;\n",
      "        }\n",
      "        \n",
      "        .badge-date {\n",
      "            font-size: 12px;\n",
      "            color: #666;\n",
      "        }\n",
      "        \n",
      "        .tag-container {\n",
      "            margin-top: 20px;\n",
      "        }\n",
      "        \n",
      "        .tag-item {\n",
      "            display: flex;\n",
      "            justify-content: space-between;\n",
      "            align-items: center;\n",
      "            padding: 15px 0;\n",
      "            border-bottom: 1px solid #eee;\n",
      "        }\n",
      "        \n",
      "        .tag-label {\n",
      "            background-color: #f0f0f0;\n",
      "            padding: 4px 12px;\n",
      "            border-radius: 4px;\n",
      "            font-size: 14px;\n",
      "            font-weight: 500;\n",
      "        }\n",
      "        \n",
      "        .tag-stats {\n",
      "            display: flex;\n",
      "            gap: 20px;\n",
      "            font-size: 14px;\n",
      "            color: #666;\n",
      "        }\n",
      "        \n",
      "        .tag-stats span {\n",
      "            font-weight: 500;\n",
      "        }\n",
      "        \n",
      "        .tag-stats .posts {\n",
      "            color: #333;\n",
      "        }\n",
      "        \n",
      "        .tag-stats .posts-percentage {\n",
      "            color: #2c3e50;\n",
      "        }\n",
      "    </style>\n",
      "</head>\n",
      "<body>\n",
      "    <div class=\"section\">\n",
      "        <h1>About</h1>\n",
      "        <p>I am good at designing, coding, and development. I have experience designing and developing both Android and iOS apps. I am currently learning web development and deep learning.</p>\n",
      "    </div>\n",
      "    \n",
      "    <div class=\"section\">\n",
      "        <h2>Badges</h2>\n",
      "        <div class=\"badge-container\">\n",
      "            <div class=\"badge-card\">\n",
      "                <img src=\"https://via.placeholder.com/80x80/FFD700/000000?text=⭐\" alt=\"Gold Badge\" class=\"badge-icon\">\n",
      "                <p class=\"badge-text\">This user doesn't have any gold badges yet.</p>\n",
      "            </div>\n",
      "            \n",
      "            <div class=\"badge-card\">\n",
      "                <img src=\"https://via.placeholder.com/80x80/C0C0C0/000000?text=⭐\" alt=\"Silver Badge\" class=\"badge-icon\">\n",
      "                <p class=\"badge-text\">This user doesn't have any silver badges yet.</p>\n",
      "            </div>\n",
      "            \n",
      "            <div class=\"badge-card\">\n",
      "                <div style=\"display: flex; align-items: center; gap: 10px;\">\n",
      "                    <img src=\"https://via.placeholder.com/80x80/B8860B/FFFFFF?text=⭐\" alt=\"Bronze Badge\" class=\"badge-icon\">\n",
      "                    <div>\n",
      "                        <h3 style=\"margin: 0; color: #2c3e50;\">4</h3>\n",
      "                        <p style=\"margin: 0; color: #666;\">bronze badges</p>\n",
      "                    </div>\n",
      "                </div>\n",
      "                <ul class=\"badge-list\">\n",
      "                    <li class=\"badge-item\">\n",
      "                        <span class=\"badge-label\">Supporter</span>\n",
      "                        <span class=\"badge-date\">Mar 3, 2022</span>\n",
      "                    </li>\n",
      "                    <li class=\"badge-item\">\n",
      "                        <span class=\"badge-label\">Teacher</span>\n",
      "                        <span class=\"badge-date\">Dec 5, 2020</span>\n",
      "                    </li>\n",
      "                    <li class=\"badge-item\">\n",
      "                        <span class=\"badge-label\">Scholar</span>\n",
      "                        <span class=\"badge-date\">Apr 5, 2020</span>\n",
      "                    </li>\n",
      "                </ul>\n",
      "            </div>\n",
      "        </div>\n",
      "    </div>\n",
      "    \n",
      "    <div class=\"section\">\n",
      "        <h2>Top tags</h2>\n",
      "        <div class=\"tag-container\">\n",
      "            <div class=\"tag-item\">\n",
      "                <span class=\"tag-label\">android</span>\n",
      "                <div class=\"tag-stats\">\n",
      "                    <span>1 score</span>\n",
      "                    <span>1 posts</span>\n",
      "                    <span class=\"posts-percentage\">100 posts %</span>\n",
      "                </div>\n",
      "            </div>\n",
      "            <div class=\"tag-item\">\n",
      "                <span class=\"tag-label\">flutter</span>\n",
      "                <div class=\"tag-stats\">\n",
      "                    <span>1 score</span>\n",
      "                    <span>1 posts</span>\n",
      "                    <span class=\"posts-percentage\">100 posts %</span>\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "    </div>\n",
      "</body>\n",
      "</html>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": \"scratch_ss.png\",\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Give HTML and CSS for the reference UI.\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "# Preparation for inference\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "inputs = inputs.to(model.device)\n",
    "\n",
    "# Inference: Generation of the output\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=4096)\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")\n",
    "print(output_text[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
