{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen3-VL-2B GRPO Training: UI Screenshot â†’ HTML/CSS\n",
    "\n",
    "Train a Vision Language Model to generate HTML+Tailwind CSS from website screenshots using GRPO.\n",
    "\n",
    "- **Model**: Qwen3-VL-2B-Instruct (LoRA)\n",
    "- **Dataset**: WebSight v0.2 (1% subset)\n",
    "- **Rewards**: format (0.1), HTML validity (0.2), visual fidelity/SSIM (0.5), structural similarity (0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import GRPOTrainer, GRPOConfig\n",
    "\n",
    "from vcoder import (\n",
    "    format_reward,\n",
    "    html_validity_reward,\n",
    "    visual_fidelity_reward,\n",
    "    structural_similarity_reward,\n",
    ")\n",
    "from vcoder.data.websight import load_websight_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "model_id = \"Qwen/Qwen3-VL-2B-Instruct\"\nprocessor = AutoProcessor.from_pretrained(model_id, use_fast=True, padding_side=\"left\")\n\n# Streams from HuggingFace (no full download), filters, and materializes into a regular Dataset\ntrain_dataset = load_websight_dataset(max_samples=2000)\nprint(f\"Training samples: {len(train_dataset)}\")\nprint(f\"Columns: {train_dataset.column_names}\")\nprint(f\"Sample image size: {train_dataset[0]['image'].size}\")\nprint(f\"Sample HTML length: {len(train_dataset[0]['solution'])} chars\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model + LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,422,528 || all params: 2,133,954,560 || trainable%: 0.3010\n"
     ]
    }
   ],
   "source": [
    "model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure GRPO Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = GRPOConfig(\n",
    "    output_dir=\"Qwen3-VL-2B-HTMLCSS\",\n",
    "    learning_rate=5e-6,\n",
    "    remove_unused_columns=False,\n",
    "    num_train_epochs=1,\n",
    "    bf16=True,\n",
    "\n",
    "    # Batch / generation parameters\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    max_completion_length=2048,\n",
    "    num_generations=4,\n",
    "    # max_length=4096,\n",
    "\n",
    "    # Reporting and saving\n",
    "    report_to=[\"tensorboard\"],\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=25,\n",
    "    save_total_limit=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize Trainer and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Iterable datasets are not yet supported in GRPOTrainer. Please use a standard dataset instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mGRPOTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreward_funcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mformat_reward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhtml_validity_reward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvisual_fidelity_reward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstructural_similarity_reward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# reward_weights=[0.1, 0.2, 0.5, 0.2],\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/dev/shm/vcoder3/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py:511\u001b[0m, in \u001b[0;36mGRPOTrainer.__init__\u001b[0;34m(self, model, reward_funcs, args, train_dataset, eval_dataset, processing_class, reward_processing_classes, callbacks, optimizers, peft_config, tools, rollout_func)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshuffle_dataset \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mshuffle_dataset\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(train_dataset, IterableDataset)\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(eval_dataset, IterableDataset)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m ):\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;66;03m# See https://github.com/huggingface/trl/issues/3213\u001b[39;00m\n\u001b[0;32m--> 511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterable datasets are not yet supported in GRPOTrainer. Please use a standard dataset instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m     )\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mloss_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msapo\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (args\u001b[38;5;241m.\u001b[39msapo_temperature_neg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m args\u001b[38;5;241m.\u001b[39msapo_temperature_pos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen using `sapo` loss, both `sapo_temperature_neg` and `sapo_temperature_pos` must be set.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    518\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Iterable datasets are not yet supported in GRPOTrainer. Please use a standard dataset instead."
     ]
    }
   ],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    processing_class=processor,\n",
    "    reward_funcs=[\n",
    "        format_reward,\n",
    "        html_validity_reward,\n",
    "        visual_fidelity_reward,\n",
    "        structural_similarity_reward,\n",
    "    ],\n",
    "    # reward_weights=[0.1, 0.2, 0.5, 0.2],\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Final Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"Qwen3-VL-2B-HTMLCSS/final\")\n",
    "processor.save_pretrained(\"Qwen3-VL-2B-HTMLCSS/final\")\n",
    "print(\"Training complete. Adapter saved to Qwen3-VL-2B-HTMLCSS/final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. TensorBoard\n",
    "\n",
    "Launch TensorBoard to monitor training:\n",
    "```bash\n",
    "tensorboard --logdir=./Qwen3-VL-2B-HTMLCSS/runs --host=0.0.0.0 --port=6006\n",
    "```\n",
    "\n",
    "Port forward from local machine:\n",
    "```bash\n",
    "ssh -L 6006:localhost:6006 cn17-dgx -p 4422\n",
    "```\n",
    "\n",
    "Key metrics:\n",
    "- `reward` - overall average (should trend up)\n",
    "- `rewards/visual_fidelity_reward/mean` - most important signal\n",
    "- `rewards/format_reward/mean` - should converge quickly to ~0.8-1.0\n",
    "- `completions/clipped_ratio` - should be <0.2\n",
    "- `completions/mean_length` - expect 500-1500 tokens\n",
    "- `entropy` - gradual decrease"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}